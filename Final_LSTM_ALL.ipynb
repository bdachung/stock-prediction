{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhuH608KK5Cj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Dense, LSTM\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"my-drive\")"
      ],
      "metadata": {
        "id": "8SyEnfFRZ-cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "tqMbXw4iRqQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read"
      ],
      "metadata": {
        "id": "VbCcKrZsWST1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"my-drive/MyDrive/ACB_2015.csv\"\n",
        "\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "IO63Wn4_V00k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['close'])"
      ],
      "metadata": {
        "id": "FWJSvjMZdEmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization\n"
      ],
      "metadata": {
        "id": "ul8JVJ1MWXNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),(df['close']))\n",
        "plt.xticks(range(0,df.shape[0],1951),df['date'].loc[::1951])\n",
        "plt.xlabel('Date',fontsize=18)\n",
        "plt.ylabel('Close Price',fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J1IKyaYpWaPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Train & Validation & Test"
      ],
      "metadata": {
        "id": "BBLNVIIUXVcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prices = df['close'].to_numpy()\n",
        "\n",
        "df_length = df.shape[0]\n",
        "train_length = df_length * 90 // 100\n",
        "test_length = df_length * 10 // 100\n",
        "\n",
        "print(\"Train: {} \\n\\nTest: {}\".format(train_length, test_length))\n",
        "\n",
        "train_data = prices[:train_length]\n",
        "test_data = prices[train_length:]"
      ],
      "metadata": {
        "id": "WYHvgQiHXa78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process"
      ],
      "metadata": {
        "id": "NyQwZs7-ewq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Step Ahead Prediction via Averaging"
      ],
      "metadata": {
        "id": "4uqhjhiGe5-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Standard Average "
      ],
      "metadata": {
        "id": "ZlbC7VQIe7Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 20\n",
        "N = train_data.size\n",
        "std_avg_predictions = []\n",
        "std_avg_x = []\n",
        "mse_errors = []\n",
        "\n",
        "for pred_idx in range(window_size,N):\n",
        "\n",
        "    if pred_idx >= N:\n",
        "        date = dt.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
        "    else:\n",
        "        date = df.loc[pred_idx,'date']\n",
        "\n",
        "    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
        "    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\n",
        "    std_avg_x.append(date)"
      ],
      "metadata": {
        "id": "Dla9p3UVexjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),df['close'],color='b',label='True')\n",
        "plt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Prediction')\n",
        "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Standard Average Price')\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OBDfiSV6fZsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exponential Moving Average"
      ],
      "metadata": {
        "id": "dfUg2PRytM7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = train_data.size\n",
        "\n",
        "run_avg_predictions = []\n",
        "run_avg_x = []\n",
        "\n",
        "mse_errors = []\n",
        "\n",
        "running_mean = 0.0\n",
        "run_avg_predictions.append(running_mean)\n",
        "\n",
        "decay = 0.5\n",
        "\n",
        "for pred_idx in range(1,N):\n",
        "\n",
        "    running_mean = running_mean*decay + (1.0-decay)*train_data[pred_idx-1]\n",
        "    run_avg_predictions.append(running_mean)\n",
        "    mse_errors.append((run_avg_predictions[-1]-train_data[pred_idx])**2)\n",
        "    run_avg_x.append(date)\n",
        "\n",
        "print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))"
      ],
      "metadata": {
        "id": "yCqiNaVatOOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),df['close'],color='b',label='True')\n",
        "plt.plot(range(0,N),run_avg_predictions,color='orange', label='Prediction')\n",
        "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Exponential Moving Average Price')\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sUEPwauptX4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find baseline"
      ],
      "metadata": {
        "id": "vjgI4S-AtLOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_base_line(file_name, stock_name):\n",
        "  df = pd.read_csv(file_name).sort_values('date')\n",
        "  prices = df['close'].to_numpy()\n",
        "\n",
        "  df_length = df.shape[0]\n",
        "  train_length = df_length * 90 // 100\n",
        "  test_length = df_length * 10 // 100\n",
        "\n",
        "  train_data = prices[:train_length]\n",
        "  test_data = prices[train_length:]\n",
        "\n",
        "  N = test_data.size\n",
        "\n",
        "  run_avg_predictions = []\n",
        "  run_avg_x = []\n",
        "\n",
        "  mse_errors = []\n",
        "\n",
        "  running_mean = df['close'][train_length]\n",
        "  run_avg_predictions.append(running_mean)\n",
        "\n",
        "  decay = 0.5\n",
        "\n",
        "  for pred_idx in range(1,N):\n",
        "      running_mean = running_mean*decay + (1.0-decay)*test_data[pred_idx-1]\n",
        "      run_avg_predictions.append(running_mean)\n",
        "      mse_errors.append((run_avg_predictions[-1]-test_data[pred_idx])**2)\n",
        "      run_avg_x.append(date)\n",
        "\n",
        "  plt.figure(figsize = (18,9))\n",
        "  plt.plot(range(test_length+1),df[train_length:]['close'],color='b',label='True')\n",
        "  plt.plot(range(0,N),run_avg_predictions,color='orange', label='Prediction')\n",
        "  plt.xlabel(stock_name)\n",
        "  plt.ylabel('Exponential Moving Average Price')\n",
        "  plt.legend(fontsize=18)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"============== {} ==============\".format(stock_name))\n",
        "  print(\"MSE: {}\".format(mean_squared_error(df[train_length:]['close'], run_avg_predictions)))\n",
        "  print(\"MAPE: {}\".format(mean_absolute_percentage_error(df[train_length:]['close'], run_avg_predictions)))\n",
        "  print(\"MAE: {}\".format(mean_absolute_error(df[train_length:]['close'], run_avg_predictions)))\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "O8f9rWAltLDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list = [\"ACB\", \"BID\", \"BVH\", \"CTG\", \"FPT\", \"AGR\"]\n",
        "file_name_list = []\n",
        "\n",
        "for s in stock_list:\n",
        "  file_name_list.append(\"my-drive/MyDrive/\" + s + \"_2015.csv\")\n",
        "\n",
        "\n",
        "for i in range(0, len(file_name_list)):\n",
        "  find_base_line(file_name_list[i], stock_list[i])\n"
      ],
      "metadata": {
        "id": "RC6lMZ_itKRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "1NwBJ_Kstl1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.reshape(-1,1)\n",
        "test_data = test_data.reshape(-1,1)"
      ],
      "metadata": {
        "id": "0JRdLuxd8BcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps = 3\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(time_steps, train_data.shape[0]):\n",
        "    x_train.append(train_data[i - time_steps:i])\n",
        "    y_train.append(train_data[i, 0])\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(time_steps, test_data.shape[0]):\n",
        "    x_test.append(test_data[i - time_steps:i])\n",
        "    y_test.append(test_data[i, 0])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "mEGgtlRjz2Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# 1st layer with Dropout regularisation\n",
        "# * units = add 100 neurons is the dimensionality of the output space\n",
        "# * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "# * input_shape => Shape of the training dataset\n",
        "model.add(LSTM(units=100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "# 20% of the layers will be dropped\n",
        "model.add(Dropout(0.2))\n",
        "# 2nd LSTM layer\n",
        "# * units = add 50 neurons is the dimensionality of the output space\n",
        "# * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "# 20% of the layers will be dropped\n",
        "model.add(Dropout(0.2))\n",
        "# 3rd LSTM layer\n",
        "# * units = add 50 neurons is the dimensionality of the output space\n",
        "# * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "# 50% of the layers will be dropped\n",
        "model.add(Dropout(0.5))\n",
        "# 4th LSTM layer\n",
        "# * units = add 50 neurons is the dimensionality of the output space\n",
        "model.add(LSTM(units=50))\n",
        "# 50% of the layers will be dropped\n",
        "model.add(Dropout(0.5))\n",
        "# Dense layer that specifies an output of one unit\n",
        "model.add(Dense(units=1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ITsk0FQt0H1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defined_metrics = [\n",
        "    tf.keras.metrics.MeanSquaredError(name='MSE')\n",
        "]\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=defined_metrics)\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test),\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "id": "1r97-Vcw1hfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model.predict(x_test)"
      ],
      "metadata": {
        "id": "77-XWVWCJl2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MSE: {}\".format(mean_squared_error(y_test, y_predict)))\n",
        "print(\"MAPE: {}\".format(mean_absolute_percentage_error(y_test, y_predict)))\n",
        "print(\"MAE: {}\".format(mean_absolute_error(y_test, y_predict)))"
      ],
      "metadata": {
        "id": "kaM20pIts02a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "print(y_test.shape[0])\n",
        "plt.plot(range(y_test.shape[0]),y_test,color='b',label='True')\n",
        "plt.plot(range(y_predict.shape[0]),y_predict,color='orange',label='Prediction')\n",
        "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Predict LSTM')\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPOer3vPKoO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_LSTM(file_name, stock_name):\n",
        "  df = pd.read_csv(file_name).sort_values('date')\n",
        "  prices = df['close'].to_numpy()\n",
        "\n",
        "  df_length = df.shape[0]\n",
        "  train_length = df_length * 90 // 100\n",
        "  test_length = df_length * 10 // 100\n",
        "\n",
        "  train_data = prices[:train_length]\n",
        "  test_data = prices[train_length:]\n",
        "\n",
        "  train_data = train_data.reshape(-1,1)\n",
        "  test_data = test_data.reshape(-1,1)\n",
        "\n",
        "  time_steps = 3\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for i in range(time_steps, train_data.shape[0]):\n",
        "      x_train.append(train_data[i - time_steps:i])\n",
        "      y_train.append(train_data[i, 0])\n",
        "\n",
        "  x_train = np.array(x_train)\n",
        "  y_train = np.array(y_train)\n",
        "\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "\n",
        "  for i in range(time_steps, test_data.shape[0]):\n",
        "      x_test.append(test_data[i - time_steps:i])\n",
        "      y_test.append(test_data[i, 0])\n",
        "\n",
        "  x_test = np.array(x_test)\n",
        "  y_test = np.array(y_test)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units=100, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units=50, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(units=50, return_sequences=True))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(LSTM(units=50))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=1))\n",
        "  model.summary()\n",
        "\n",
        "  defined_metrics = [\n",
        "    tf.keras.metrics.MeanSquaredError(name='MSE')\n",
        "  ]\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=defined_metrics)\n",
        "  history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test),\n",
        "                      callbacks=[callback])\n",
        "  \n",
        "  y_predict = model.predict(x_test)\n",
        "\n",
        "  plt.figure(figsize = (18,9))\n",
        "  print(y_test.shape[0])\n",
        "  plt.plot(range(y_test.shape[0]),y_test,color='b',label='True')\n",
        "  plt.plot(range(y_predict.shape[0]),y_predict,color='orange',label='Prediction')\n",
        "  #plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Predict LSTM')\n",
        "  plt.legend(fontsize=18)\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"============== {} ==============\".format(stock_name))\n",
        "  print(\"MSE: {}\".format(mean_squared_error(y_test, y_predict)))\n",
        "  print(\"MAPE: {}\".format(mean_absolute_percentage_error(y_test, y_predict)))\n",
        "  print(\"MAE: {}\".format(mean_absolute_error(y_test, y_predict)))\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "VZQjJGzpyXtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list = [\"BID\", \"BVH\", \"CTG\", \"FPT\", \"AGR\", \"ACB\"]\n",
        "file_name_list = []\n",
        "\n",
        "for s in stock_list:\n",
        "  file_name_list.append(\"my-drive/MyDrive/\" + s + \"_2015.csv\")\n",
        "\n",
        "\n",
        "for i in range(0, len(file_name_list)):\n",
        "  predict_LSTM(file_name_list[i], stock_list[i])\n"
      ],
      "metadata": {
        "id": "B_U8NbYwyUui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another stock"
      ],
      "metadata": {
        "id": "PEsew-1MM10G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_another_stock(file_name, stock_name):\n",
        "  df = pd.read_csv(file_name).sort_values('date')\n",
        "\n",
        "  # plt.figure(figsize = (18,9))\n",
        "  # plt.plot(range(df.shape[0]),(df['close']))\n",
        "  # plt.xticks(range(0,df.shape[0],1951),df['date'].loc[::1951])\n",
        "  # plt.xlabel('Date',fontsize=18)\n",
        "  # plt.ylabel('Close Price',fontsize=18)\n",
        "  # plt.show()\n",
        "\n",
        "  prices = df['close'].to_numpy()\n",
        "\n",
        "  test_data = prices\n",
        "  # test_data = prices[1561:]\n",
        "\n",
        "  print(\"Test: {}\".format(test_data.shape[0]))\n",
        "\n",
        "  test_data = test_data.reshape(-1,1)\n",
        "\n",
        "  y_test = []\n",
        "  x_test = []\n",
        "\n",
        "  time_steps = 3\n",
        "\n",
        "  for i in range(time_steps, test_data.shape[0]):\n",
        "      x_test.append(test_data[i - time_steps:i])\n",
        "      y_test.append(test_data[i, 0])\n",
        "\n",
        "  x_test = np.array(x_test)\n",
        "  y_test = np.array(y_test)\n",
        "  \n",
        "  y_predict = model.predict(x_test)\n",
        "\n",
        "  plt.figure(figsize = (18,9))\n",
        "  plt.plot(range(y_test.shape[0]),y_test,color='b',label='True')\n",
        "  plt.plot(range(y_predict.shape[0]),y_predict,color='orange',label='Prediction')\n",
        "  plt.xlabel(stock_name)\n",
        "  plt.ylabel('Predict LSTM')\n",
        "  plt.legend(fontsize=18)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "PAnCVABfRIO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_list = [\"BID\", \"BVH\", \"CTG\", \"FPT\", \"AGR\"]\n",
        "file_name_list = []\n",
        "\n",
        "for s in stock_list:\n",
        "  file_name_list.append(\"my-drive/MyDrive/\" + s + \"_2015.csv\")\n",
        "\n",
        "\n",
        "for i in range(0, len(file_name_list)):\n",
        "  evaluate_another_stock(file_name_list[i], stock_list[i])\n"
      ],
      "metadata": {
        "id": "mvFjI1LmRzZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}